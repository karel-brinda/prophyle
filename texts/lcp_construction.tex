\documentclass[12pt]{article}
\usepackage{fullpage}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

\bibliographystyle{plain}

\begin{document}
\thispagestyle{empty}

\title{0-1 LCP construction}
\author{Karel Brinda \and Gregory Kucherov \and Kamil Salikhov}
\maketitle

{\bf Goal:} 

for given $k$-mer length construct "zero-one" $LCP$ array ($kLCP$) ($KLCP[i] = 0$ if $LCP[i] < k-1$ and $1$ otherwise) using FM-index, without full SA.

{\bf Algorithm:}

Let's backtrack through all $(k-1)$-mers and try to find them in $FM$-index. If at any step we obtain empty $SA$-interval, we stop this branch of backtracking (first heuristic).
If at any moment we have $SA$-interval with only 1 element - we stop this branch (second heuristics).

If we find any $(k-1)$-mer in $FM$-index, and SA-interval is at least of size $2$ - we put $1$'s in corresponding cells of $kLCP$.

And finally we put $0$'s (this means that $LCP[i]$ is less than $k-1$) for all values in $kLCP$ that were not touched during backtracking.

In general case algorithm works in $O(Nk)$ time, where $N$ is size of $SA$.

{\bf Proof of asymptotics:} 

The whole backtracking can be considered as traversing a tree. We can stop in some node $V$ with corresponding SA-interval $(x, y)$ for two reasons: 
1) $x > y$ ($SA$-interval is empty). In this case the parent of $V$ has non-stopping branch (or stopping by second heuristics), the number of non-stopping branches is up to $N$, so the number of stopping nodes is up to $Nk$ (number of nodes in non-stopping branches) multiplied by $4$ (size of alphabet).
2) $x = y$. For each such branch there is an element in SA, so number of nodes in such branches is up to $Nk$ again. 

So, finally we can traverse up to $4Nk + Nk + N = O(Nk)$ vertices in a tree. 

{\bf Experimental results:}

We tested our construction algorithm on drosophilla genome (about 117 millions bases).

BWT construction time is $155$ seconds.

\begin{table}[!tb]
\caption{
%Values of $\numstrings(\scheme,4,88M,m)$ 
$0-1$ LCP array construction time for drosophilla genome (117 millions bases) for different values of $k$.
\label{tab:constr_time}}
\centering
\begin{tabular}{| c | c | }
  \hline
  k & time (sec) \\ 
  \hline
  15 & 28 \\
  \hline
  20 & 59 \\
  \hline
  25 & 66 \\
  \hline
  30 & 86 \\
  \hline
\end{tabular}
\end{table}

{\bf $K$-mer matching algorithm}

We want to match every $k$-mer from read of length $n$ to corresponding chromosome (node..) in genome. This can be done independently for each $k$-mer, and working time will be $O(n-k) \cdot T(k) = O(N) \cdot T(k)$, where $T(k)$ -- matching time of one $k$-mer. 

{\bf Sliding window approach}

Suppose that we are matching two consequtive $k$-mers using backward search in $FM$-index, $k_1 = xA$ and $k_2 = Ay$. Suppose we found non-empty $SA$-interval $(p, q)$ for $k_2$. To find $SA$-interval for $k_1$, we need to ``remove`` last character from $k_2$, and continue with backward search, adding character $x$. In terms of $SA$-interval, removing character from the end of $k$-mer means increasing $SA$-interval, e.g. decreasing $p$ and increasing $q$. This can be easily done using $kLCP$ array -- we decrease $p$ while $kLCP[p-1] = 1$ (this means that suffixes $p-1$ and $p$ have at least $k-1$ common characters) and increase $q$ while $kLCP[q] = 1$ (for the same reason).

If decreasment of $p$ and increasment of $q$ are small, finding $SA$-interval for $k_1$ having non-empty $SA$ interval for $k_2$ works in time, needed for increasing query by one character during backward search. To limit decreasment of $p$ and increasment of $q$, we can use some structure that allows rank-minimum queries. But for simplicity, we use another approach: for every $B$-th index (where $B$ is some constant) in $kLCP$ we store exact answer -- index where we stop decreasing $p$ while $kLCP[p-1]$ = 1. This allows us find $SA$ interval for $k_1$ in $O(B)$ time. The same holds for increasing $q$.

{\bf Storing nodes array instead of sampled suffix array}

For every $k$-mer, we need to know only chromosome id(s), not exact position in the genome. This means that instead of storing sampled suffix array (to obtain position in genome from $SA$-position, and then chromosome id) we can store only ``sampled node ids array`` -- e.g., store corresponing node ids for sampled set of $SA$-positions. This can reduce amount of memory used by structure, and can speed up computations (by skipping the step when we get chromosome id from position in genome).

But this approach also face up with difficulty: $BWA$ concatenates chromosomes without any separator between them, and some $k$-mers can match on the border of two consequtive chromosomes. This results in ``false positive`` matches, and as we don't know exact position in genome, we can not determine such situations. The solution is to add some auxilliary values in sampled node array, that correspond to indexes on the border of two chromosomes. Suppose that chromosome $c_1$ ends at position $999$ and chromosome $c_2$ starts at position $1000$. Suppose that we search for $k$-mers with $k=25$. Then, we add position $1000-25 = 975$ in sampled node array with value $-1$ and position $1000$ with value $2$ (and nothing between them!). This means that when we try to find node id for positions from $975$ to $999$, we will get $-1$ as answer. And this will indicate that position is on the border of two chromosomes.

\end{document}